{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a438676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ast\n",
    "\n",
    "from fontTools.ttLib import TTFont\n",
    "from fontTools.pens.svgPathPen import SVGPathPen\n",
    "\n",
    "import svgpath2mpl\n",
    "from svgpath2mpl import parse_path\n",
    "from svgutils.compose import *\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d2dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfo = 'ghost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da832f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../ff/'\n",
    "#os.listdir(fdir)\n",
    "fnam = 'ff_c2.ttf'\n",
    "font = TTFont(fdir+fnam)\n",
    "cmap = font.getBestCmap()\n",
    "cmapv = list(cmap.values())\n",
    "# cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4da33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cdict1.txt') as f:\n",
    "    data = f.read()\n",
    "cdict = ast.literal_eval(data)\n",
    "clist = list(cdict.keys())\n",
    "#cdict['ū']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef35f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdir = '../../writ/'\n",
    "tfil = 'ghost.txt'\n",
    "#sorted(os.listdir(tdir))\n",
    "#\n",
    "my_tfil = open(tdir+tfil, \"r\")\n",
    "data = my_tfil.read()\n",
    "my_tfil.close()\n",
    "data = data.split(\"\\n\")\n",
    "data = [d for d in data if d != \"#\"]\n",
    "data = [d for d in data if d != \"# ~~~~~~~~~~\"]\n",
    "#data\n",
    "#\n",
    "pind = [i for i in range(len(data)) if \"# pg\" in data[i]]\n",
    "pages = [data[pind[ii]:pind[ii+1]] for ii in range(len(pind)-1)]\n",
    "pages.append(data[pind[len(pind)-1]:len(data)])\n",
    "#pages[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90108d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# for p in tqdm(range(len(pages))):\n",
    "for p in tqdm(range(0,1)):\n",
    "# for p in tqdm(range(11,12)):\n",
    "    pp = p\n",
    "    #\n",
    "    #pp = 1 ## set page\n",
    "    txts = pages[pp]\n",
    "    pg = [t for t in txts if \"# pg\" in t]\n",
    "    pg = pg[0].replace(\"# \",\"\")\n",
    "    txts = [t for t in txts if \"# pg\" not in t]\n",
    "    txts = [t for t in txts if t != '']\n",
    "    #txts\n",
    "    #\n",
    "    # size correction\n",
    "    # english, punctuation, pinyin, hanzi\n",
    "    csca = {\n",
    "        \"engl\": 1,\n",
    "        \"punc\": 1,\n",
    "        \"piny\": 1,\n",
    "        \"hanz\": 2.25,\n",
    "    }\n",
    "    csca[\"engl\"]\n",
    "    #\n",
    "    tcs = []\n",
    "    ics = []\n",
    "    pg_miss_c = []\n",
    "    for x in range(len(txts)):\n",
    "        txt = txts[x]\n",
    "        tc = []\n",
    "        ic = []\n",
    "        for t in range(len(txt)):\n",
    "            char = txt[t]\n",
    "            charr = char.encode(\"unicode_escape\")\n",
    "            charr = str(charr)\n",
    "            ctyp = \"\"\n",
    "            if len(charr) <5:\n",
    "                if char in clist: # English\n",
    "                    charrie = cdict[char]\n",
    "                    ctyp = \"engl\"\n",
    "                else: # Common punctuation\n",
    "                    charrie = char\n",
    "                    ctyp = \"punc\"\n",
    "            else:\n",
    "                if char in clist: # Pinyin symbols\n",
    "                    charrie = cdict[char]                    \n",
    "                    ctyp = \"piny\"\n",
    "                else: # Chinese characters\n",
    "                    charr = charr.replace(\"b'\\\\\\\\\",\"'\\\\\\\\\")\n",
    "                    charr = charr.replace(\"'\",\"\")\n",
    "                    charr = charr.replace(\"\\\\\\\\\",\"\")\n",
    "                    charr = charr.upper()\n",
    "                    charrie = charr.replace(\"U\",\"uni\")                  \n",
    "                    ctyp = \"hanz\"\n",
    "                    if charrie not in cmapv:\n",
    "                        pg_miss_c.append(char)                    \n",
    "            tc.append(csca[ctyp])\n",
    "            ic.append(charrie)\n",
    "        tcs.append(tc)\n",
    "        ics.append(ic)\n",
    "    #\n",
    "    # print('custom font')\n",
    "    # print('no of chars: '+str(len(cmapv)))\n",
    "    # chic = [c for c in cmapv if \"uni\" in c]\n",
    "    # print('no of chinese chars: '+str(len(chic)))\n",
    "    # print('missing characters')\n",
    "    # print(len(set(pg_miss_c)))\n",
    "    # set(pg_miss_c)\n",
    "    #\n",
    "    for x in range(len(txts)):\n",
    "        if x >= 0: # use for subset\n",
    "            #x = 14\n",
    "            #print(x)\n",
    "            txt = txts[x]\n",
    "            # txt='Nǐ hǎo, nǐ zěnme yàng'\n",
    "            # txt\n",
    "            sca = 1\n",
    "            gpx = 10\n",
    "            gpy = 10\n",
    "    #         print(\"len:\")\n",
    "    #         print(len(txt))\n",
    "    #         print(sum(tcs[x]))\n",
    "            fig, axs = plt.subplots(1, \n",
    "                                    len(txt), \n",
    "                                    figsize=((sum(tcs[x])*sca)/4, np.mean(tcs[x])))\n",
    "            for t in range(len(txt)):\n",
    "                char = txt[t]\n",
    "                charrie = ics[x][t]\n",
    "                #\n",
    "                if char != ' ': # Handle spaces\n",
    "                    glyphSet = font.getGlyphSet()\n",
    "                    svgpen = SVGPathPen(glyphSet)\n",
    "                    glyph = glyphSet[charrie]\n",
    "                    #\n",
    "                    glyph.draw(svgpen)\n",
    "                    cpath = svgpen.getCommands()\n",
    "                    cpath = cpath.replace('Z','') # replace 'Z' = 'closepath'\n",
    "                    #cpath\n",
    "                    #\n",
    "                    pcpath = svgpath2mpl.parse_path(cpath)\n",
    "                    vv = pcpath.vertices\n",
    "                    vdf = pd.DataFrame(vv)\n",
    "                    vxmi = vdf[0].min()\n",
    "                    vxma = vdf[0].max()\n",
    "                    vymi = vdf[1].min()\n",
    "                    vyma = vdf[1].max()\n",
    "                    #\n",
    "                    #\n",
    "                    patch = mpl.patches.PathPatch(\n",
    "                        pcpath, \n",
    "                        facecolor='none', \n",
    "                        edgecolor='black', \n",
    "                        linewidth=1)\n",
    "                    patch.set_transform(axs[t].transData)\n",
    "                    axs[t].add_patch(patch)\n",
    "                    axs[t].set_aspect(1)\n",
    "                    axs[t].axis(\"off\")\n",
    "                    axs[t].set_xticklabels([])\n",
    "                    axs[t].set_yticklabels([])\n",
    "                    axs[t].set_xlim([vxmi-50, vxma+50])\n",
    "                    axs[t].set_ylim([-350, 1100])\n",
    "                else: # space character\n",
    "                    axs[t].set_aspect(1)\n",
    "                    axs[t].axis(\"off\")\n",
    "                    axs[t].set_xlim([0, 400])\n",
    "                    axs[t].set_ylim([-350, 1100])\n",
    "            #\n",
    "            fig.subplots_adjust(left=0, wspace=0, hspace=0)\n",
    "            fig.patch.set_facecolor('xkcd:mint green')\n",
    "            plt.savefig(\"out/\"+outfo+\"/\"+pg+\"_l\"+str(\"{:02d}\".format(x))+\".svg\")\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "    #\n",
    "    # for t in range(len(txts)):\n",
    "    #     print(t)\n",
    "    #     print(txts[t])\n",
    "    #\n",
    "    # concatenate page text\n",
    "    #\n",
    "    spp = pg\n",
    "    svgs = sorted(os.listdir('./out/'+outfo+'/'))\n",
    "    svgs = [s for s in svgs if spp in s]\n",
    "    svgs = [s for s in svgs if 'stack' not in s]\n",
    "    #\n",
    "    s_p0 = 'Figure(\"0.375cm\", \"0.375cm\",' # not actually cm\n",
    "    s_p1 = 'Panel(SVG(\"out/'+outfo+'/'\n",
    "    s_p2 = '\").scale(0.015)), '\n",
    "    s_pn = ').tile(1,'+str(len(svgs))+').save(\"out/'+outfo+'/'+spp+'_stack.svg\")'\n",
    "    #\n",
    "    s_pl = []\n",
    "    s_pl.append(s_p0)\n",
    "    for s in svgs:\n",
    "        s_pl.append(s_p1+s+s_p2)\n",
    "    s_pl.append(s_pn)\n",
    "    #\n",
    "    sfun = ''.join(s_pl)\n",
    "    eval(sfun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e689e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
